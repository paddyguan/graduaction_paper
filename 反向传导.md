# 反向传导







![img](https://images2015.cnblogs.com/blog/853467/201606/853467-20160630140644406-409859737.png)



![img](https://images2015.cnblogs.com/blog/853467/201606/853467-20160630141449671-1058672778.png)



1.总误差：(square error)

$E_{totoal} = \sum \frac{1}{2}(target-output)^2$



但是有n个输出，所以分别计算n个output的误差，总误差为n个误差之和

$E_{1} = \sum \frac{1}{2}(target_{1}-output_{1})^2$

$E_{n} = \sum \frac{1}{2}(target_{n}-output_{n})^2$

$E_{totoal} = \sum_1^2 E_{n}$



2.隐含层---->输出层的权值更新：

以权重参数w5为例，如果我们想知道w5对整体误差产生了多少影响，可以用整体误差对w5求偏导求出：（链式法则）



${\partial E_{total} \over \partial \omega_5 } = {\partial E_{total} \over \partial out_{o1}} *  {\partial out_{o1} \over \partial net_{o1}} *  {\partial net_{o1} \over \partial  \omega_5} $

下面的图可以更直观的看清楚误差是怎样反向传播的：



![img](https://images2015.cnblogs.com/blog/853467/201606/853467-20160630152018906-1524325812.png)





现在我们来分别计算每个式子的值：

计算${\partial E_{total} \over \partial out_{on} }$:

$E_{total} = \sum E_n = \sum {1 \over 2}(target_{on} - out_{on})^2 $

${\partial E_{total} \over \partial out_{on}}  = 2*{1 \over 2}(target_{on}- out{on}) ^{2-1}*-1 + 0$



计算${\partial out_{on} \over \partial net_{on}}$:

$out_{on} = {1 \over 1 + e^{-net_{on}}}$

${\partial out_{on} \over \partial net_{on}} = out_{on}*(1-out_{on})$



这一步实际上就是对sigmoid函数求导



计算${\partial net_{on} \over \partial \omega_{n}}$:

$net_{on} = \omega_n*out_{h1} + \omega_{n+1}*out_{h2} + b_{2}*1$

${\partial net_{on} \over \partial \omega_{n}} = 1*out_{h1}*\omega_n^{1-1} + 0 + 0 = out_{h1}$



最后三者相乘：

${\partial E_{total} \over \partial \omega_5 } = {\partial E_{total} \over \partial out_{o1}} *  {\partial out_{o1} \over \partial net_{o1}} *  {\partial net_{o1} \over \partial  \omega_5} $







这样我们就计算出整体误差$E_{totoal}$对$\omega_n$的偏导值。





